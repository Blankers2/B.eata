{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdJBpHv4mPn-",
        "outputId": "8ab3786f-a51a-444b-ccb8-d97ab7736b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun 23 10:16:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import transformers, emoji, soynlp, pytorch_lightning\n",
        "except:\n",
        "    !pip install -U -q transformers emoji soynlp pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwUdbd0XYHyM",
        "outputId": "c1a73c66-0f2d-46f6-d122-555a484e1390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.8/416.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.2/812.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsjtxFNSYCoY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import emoji\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "import seaborn as sns\n",
        "import matplotlib as plt\n",
        "import glob\n",
        "from multiprocessing import Pool, cpu_count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 쿠팡"
      ],
      "metadata": {
        "id": "1jze8Flzmi4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 쿠팡 상품평 concat\n",
        "csv_files = glob.glob(os.path.join(os.getcwd(), \"product_coupang_review*.csv\"))\n",
        "dataframes = []\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file)\n",
        "    dataframes.append(df)\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "combined_df.to_csv('combined_coupang_review_2024.csv', index=False)"
      ],
      "metadata": {
        "id": "1d0L8QLgYKBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddORqvE6Lr8J"
      },
      "outputs": [],
      "source": [
        "# 코랩 T4 GPU 환경\n",
        "# 쿠팡 데이터 로드\n",
        "coupang_df = pd.read_csv('combined_coupang_reviews.csv')\n",
        "\n",
        "# 레이블 확인\n",
        "print(coupang_df['rate'].value_counts())\n",
        "\n",
        "# 다수 클래스와 소수 클래스 구분\n",
        "df_majority = coupang_df[coupang_df['rate'] == 5]\n",
        "df_minority_4 = coupang_df[coupang_df['rate'] == 4]\n",
        "df_minority_3 = coupang_df[coupang_df['rate'] == 3]\n",
        "df_minority_2 = coupang_df[coupang_df['rate'] == 2]\n",
        "df_minority_1 = coupang_df[coupang_df['rate'] == 1]\n",
        "\n",
        "# 다수 클래스 크기에 맞추어 소수 클래스 오버샘플링\n",
        "df_minority_4_upsampled = resample(df_minority_4,\n",
        "                                   replace=True,     # 샘플을 복제하여 오버샘플링\n",
        "                                   n_samples=len(df_majority),  # 다수 클래스 샘플 수에 맞추어 변경\n",
        "                                   random_state=42)  # 재현성을 위한 랜덤 시드 설정\n",
        "df_minority_3_upsampled = resample(df_minority_3,\n",
        "                                   replace=True,\n",
        "                                   n_samples=len(df_majority),\n",
        "                                   random_state=42)\n",
        "df_minority_2_upsampled = resample(df_minority_2,\n",
        "                                   replace=True,\n",
        "                                   n_samples=len(df_majority),\n",
        "                                   random_state=42)\n",
        "df_minority_1_upsampled = resample(df_minority_1,\n",
        "                                   replace=True,\n",
        "                                   n_samples=len(df_majority),\n",
        "                                   random_state=42)\n",
        "\n",
        "# 오버샘플링된 데이터프레임 결합\n",
        "df_upsampled = pd.concat([df_majority, df_minority_4_upsampled, df_minority_3_upsampled, df_minority_2_upsampled, df_minority_1_upsampled])\n",
        "\n",
        "# 데이터 확인\n",
        "print(df_upsampled['rate'].value_counts())\n",
        "df_upsampled.to_csv('coupang_reviews_oversampled.csv', index=False)\n",
        "\n",
        "# 형태소 분석기 로드\n",
        "okt = Okt()\n",
        "\n",
        "# 불용어 리스트 정의\n",
        "stopwords = [\"그\", \"이\", \"저\", \"것\", \"들\", \"의\", \"에\", \"를\", \"가\", \"은\", \"는\", \"이다\", \"하다\"]\n",
        "# stopwords = [ranks.nl의 675개 불용어 - 너무 길어서 생략]\n",
        "\n",
        "# 토크나이저 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")\n",
        "\n",
        "def preprocess_dataframe(df):\n",
        "    def clean(x):\n",
        "        emojis = ''.join(emoji.EMOJI_DATA.keys())\n",
        "        pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-힣{emojis}]+')\n",
        "        url_pattern = re.compile(\n",
        "            r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
        "        x = pattern.sub(' ', x)\n",
        "        x = url_pattern.sub('', x)\n",
        "        x = x.strip()\n",
        "        x = repeat_normalize(x, num_repeats=2)\n",
        "        return x\n",
        "\n",
        "    def remove_stopwords(x):\n",
        "        words = x.split()\n",
        "        return ' '.join([word for word in words if word not in stopwords])\n",
        "\n",
        "    def tokenize_and_remove_stopwords(text):\n",
        "        tokens = okt.morphs(text, stem=True)\n",
        "        tokens = [word for word in tokens if word not in stopwords]\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    def encode(x):\n",
        "        clean_text = clean(str(x))\n",
        "        tokenized_text = tokenize_and_remove_stopwords(clean_text)\n",
        "        return tokenizer.encode(\n",
        "            tokenized_text,\n",
        "            padding='max_length',\n",
        "            max_length=200,\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "    if 'review' in df.columns:\n",
        "        df['review'] = df['review'].map(encode)\n",
        "    elif 'review_text' in df.columns:\n",
        "        df['review_text'] = df['review_text'].map(encode)\n",
        "    else:\n",
        "        raise ValueError(\"DataFrame does not contain 'review' or 'review_text' column.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# 데이터 로드\n",
        "coupang_df = pd.read_csv('coupang_review_2024_oversampled.csv')\n",
        "kurly_df = pd.read_csv('combined_kurly_review_2024.csv')\n",
        "\n",
        "# 쿠팡 데이터 전처리\n",
        "coupang_df = coupang_df[['review', 'rate']]\n",
        "coupang_df = coupang_df.rename(columns={'rate': 'label'})\n",
        "\n",
        "# 전처리 적용\n",
        "coupang_df = preprocess_dataframe(coupang_df)\n",
        "kurly_df = preprocess_dataframe(kurly_df)\n",
        "\n",
        "# 학습 및 검증 데이터 분할\n",
        "train_df, val_df = train_test_split(coupang_df, test_size=0.2, random_state=42)\n",
        "\n",
        "class Model(LightningModule):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.clsfier = AutoModelForSequenceClassification.from_pretrained(self.hparams.pretrained_model, num_labels=5)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.hparams.pretrained_tokenizer if self.hparams.pretrained_tokenizer else self.hparams.pretrained_model\n",
        "        )\n",
        "\n",
        "    def forward(self, **kwargs):\n",
        "        return self.clsfier(**kwargs)\n",
        "\n",
        "    def step(self, batch, batch_idx):\n",
        "        data, labels = batch\n",
        "        output = self(input_ids=data, labels=labels)\n",
        "\n",
        "        loss = output.loss\n",
        "        logits = output.logits\n",
        "        preds = logits.argmax(dim=-1)\n",
        "\n",
        "        y_true = list(labels.cpu().numpy())\n",
        "        y_pred = list(preds.cpu().numpy())\n",
        "\n",
        "        return {'loss': loss, 'y_true': y_true, 'y_pred': y_pred}\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.step(batch, batch_idx)\n",
        "\n",
        "    def epoch_end(self, outputs, state='train'):\n",
        "        loss = torch.tensor(0, dtype=torch.float)\n",
        "        for i in outputs:\n",
        "            loss += i['loss'].cpu().detach()\n",
        "        loss = loss / len(outputs)\n",
        "\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for i in outputs:\n",
        "            y_true += i['y_true']\n",
        "            y_pred += i['y_pred']\n",
        "\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        prec = precision_score(y_true, y_pred, average='weighted')\n",
        "        rec = recall_score(y_true, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        self.log(state+'_loss', float(loss), on_epoch=True, prog_bar=True)\n",
        "        self.log(state+'_acc', acc, on_epoch=True, prog_bar=True)\n",
        "        self.log(state+'_precision', prec, on_epoch=True, prog_bar=True)\n",
        "        self.log(state+'_recall', rec, on_epoch=True, prog_bar=True)\n",
        "        self.log(state+'_f1', f1, on_epoch=True, prog_bar=True)\n",
        "        print(f'[Epoch {self.trainer.current_epoch} {state.upper()}] Loss: {loss}, Acc: {acc}, Prec: {prec}, Rec: {rec}, F1: {f1}')\n",
        "        return {'loss': loss}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        self.epoch_end(outputs, state='train')\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.epoch_end(outputs, state='val')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr=self.hparams.lr)\n",
        "        scheduler = ExponentialLR(optimizer, gamma=0.5)\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
        "\n",
        "    def dataloader(self, df, shuffle=False):\n",
        "        dataset = TensorDataset(\n",
        "            torch.tensor(df['review'].to_list(), dtype=torch.long),\n",
        "            torch.tensor(df['label'].to_list(), dtype=torch.long),\n",
        "        )\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.hparams.batch_size,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=self.hparams.cpu_workers,\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.dataloader(train_df, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.dataloader(val_df, shuffle=False)\n",
        "\n",
        "# 학습 준비\n",
        "args = {\n",
        "    'random_seed': 42,\n",
        "    'pretrained_model': 'beomi/kcbert-base',\n",
        "    'pretrained_tokenizer': '',\n",
        "    'batch_size': 32,\n",
        "    'lr': 5e-6,\n",
        "    'epochs': 1,\n",
        "    'max_length': 150,\n",
        "    'train_data_path': '',\n",
        "    'val_data_path': '',\n",
        "    'test_mode': False,\n",
        "    'optimizer': 'AdamW',\n",
        "    'lr_scheduler': 'exp',\n",
        "    'fp16': True,\n",
        "    'tpu_cores': 0,\n",
        "    'cpu_workers': os.cpu_count(),\n",
        "}\n",
        "\n",
        "seed_everything(args['random_seed'])\n",
        "model = Model(**args)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filename='epoch{epoch}-val_acc{val_acc:.4f}',\n",
        "    monitor='val_acc',\n",
        "    save_top_k=3,\n",
        "    mode='max',\n",
        "    auto_insert_metric_name=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    callbacks=[checkpoint_callback],\n",
        "    max_epochs=args['epochs'],\n",
        "    fast_dev_run=args['test_mode'],\n",
        "    num_sanity_val_steps=None if args['test_mode'] else 0,\n",
        "    deterministic=torch.cuda.is_available(),\n",
        "    devices=1 if torch.cuda.is_available() else None,\n",
        "    precision=16 if args['fp16'] and torch.cuda.is_available() else 32,\n",
        ")\n",
        "\n",
        "trainer.fit(model)"
      ]
    }
  ]
}